{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d99d014",
   "metadata": {},
   "source": [
    "**LangChain** is a framework for building applications powered by large language models (LLMs). It provides tools and components to make it easier to work with LLMs, handle context, manage memory, and integrate with external data sources.\n",
    "\n",
    "## Core Concepts of LangChain:\n",
    "\n",
    "1. **Components**: Building blocks (LLMs, prompts, chains, agents, memory)\n",
    "2. **Chains**: Sequences of calls to components\n",
    "3. **Agents**: Use LLMs to decide what actions to take\n",
    "4. **Memory**: Persist state between calls\n",
    "5. **Document Loaders**: Load data from various sources\n",
    "\n",
    "## Simple Example: Basic Question Answering\n",
    "\n",
    "```python\n",
    "# First install LangChain\n",
    "!pip install langchain-openai\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize the LLM (you'll need an OpenAI API key)\n",
    "llm = OpenAI(openai_api_key=\"your-api-key-here\", temperature=0.7)\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What are 3 benefits of using {product}?\",\n",
    ")\n",
    "\n",
    "# Create a chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain\n",
    "result = chain.run(\"electric cars\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output might look like:**\n",
    "```\n",
    "1. Environmental benefits with zero emissions\n",
    "2. Lower operating costs compared to gasoline vehicles  \n",
    "3. Reduced maintenance with fewer moving parts\n",
    "```\n",
    "\n",
    "## More Practical Example: Document Q&A with Retrieval\n",
    "\n",
    "```python\n",
    "!pip install langchain chromadb sentence-transformers\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Load your document (e.g., company FAQ)\n",
    "loader = TextLoader(\"company_faq.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split text into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# Create QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(openai_api_key=\"your-api-key\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# Ask questions about your document\n",
    "response = qa_chain.run(\"What is the return policy?\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "## Example: Agent with Tools\n",
    "\n",
    "```python\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(openai_api_key=\"your-api-key\", temperature=0)\n",
    "\n",
    "# Load tools (calculator and Wikipedia)\n",
    "tools = load_tools([\"llm-math\", \"wikipedia\"], llm=llm)\n",
    "\n",
    "# Initialize agent\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ask a question that requires multiple steps\n",
    "result = agent.run(\n",
    "    \"What year was the first iPhone released? \"\n",
    "    \"How many years ago was that from today?\"\n",
    ")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "## Example: With Memory for Conversation\n",
    "\n",
    "```python\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Create memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create conversation chain\n",
    "conversation = ConversationChain(\n",
    "    llm=OpenAI(openai_api_key=\"your-api-key\", temperature=0.7),\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Have a conversation\n",
    "print(conversation.predict(input=\"Hi, I'm John. I love machine learning!\"))\n",
    "print(conversation.predict(input=\"What's my name and what do I love?\"))\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "> Human: Hi, I'm John. I love machine learning!\n",
    "AI: Hello John! It's great to meet someone who loves machine learning...\n",
    "\n",
    "> Human: What's my name and what do I love?  \n",
    "AI: Your name is John and you love machine learning!\n",
    "```\n",
    "\n",
    "## Why Use LangChain?\n",
    "\n",
    "1. **Abstraction**: Simplifies complex LLM workflows\n",
    "2. **Modularity**: Mix and match components easily\n",
    "3. **Integration**: Connects to various data sources and tools\n",
    "4. **Memory**: Maintains conversation context\n",
    "5. **Agents**: Allows LLMs to use tools and take actions\n",
    "\n",
    "## Key Components in Practice:\n",
    "\n",
    "- **LLMs**: OpenAI, Anthropic, HuggingFace models\n",
    "- **Prompt Templates**: Reusable prompt structures  \n",
    "- **Chains**: Sequence of operations (summarization, Q&A, etc.)\n",
    "- **Vector Stores**: Store and retrieve document embeddings\n",
    "- **Agents**: LLMs that can use tools and make decisions\n",
    "\n",
    "LangChain is particularly useful for building:\n",
    "- Document Q&A systems\n",
    "- Chatbots with memory\n",
    "- Data analysis assistants\n",
    "- Content generation pipelines\n",
    "- Custom AI applications\n",
    "\n",
    "The framework handles the complexity of working with LLMs so you can focus on building your application logic!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

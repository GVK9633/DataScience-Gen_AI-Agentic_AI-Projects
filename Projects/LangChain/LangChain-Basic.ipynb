{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d56f8d",
   "metadata": {},
   "source": [
    "Perfect ‚úÖ ‚Äî let‚Äôs deep dive into each topic with **simple explanations + real-world examples + interview-style clarity**.\n",
    "This way, you can **explain in interviews confidently** and even write small snippets if asked.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ LangChain Basics\n",
    "\n",
    "### ‚ùì What is LangChain? Why use it over raw APIs?\n",
    "\n",
    "* **Raw LLM API (like OpenAI GPT)** ‚Üí You send a text prompt, get back text. That‚Äôs it.\n",
    "* **LangChain** ‚Üí A framework to **orchestrate LLMs with data, memory, tools, and workflows**.\n",
    "  It makes AI apps **modular, scalable, and production-ready**.\n",
    "\n",
    "**Example:**\n",
    "Raw API ‚Üí You ask GPT: *‚ÄúSummarize a PDF.‚Äù*\n",
    "But GPT doesn‚Äôt know your PDF unless you feed entire text (expensive, impractical).\n",
    "\n",
    "LangChain ‚Üí You can:\n",
    "\n",
    "1. Load the PDF\n",
    "2. Chunk it into sections\n",
    "3. Create embeddings + store in a vector DB\n",
    "4. Use retriever to pull only relevant parts\n",
    "5. Pass to LLM for summary\n",
    "\n",
    "üëâ That‚Äôs why **LangChain > Raw APIs**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Components of LangChain\n",
    "\n",
    "1. **LLM** ‚Üí The model (OpenAI GPT, Groq, Anthropic, Llama).\n",
    "\n",
    "   ```python\n",
    "   from langchain_openai import ChatOpenAI\n",
    "   llm = ChatOpenAI(model=\"gpt-4\")\n",
    "   ```\n",
    "\n",
    "2. **PromptTemplate** ‚Üí Structured, reusable prompt.\n",
    "\n",
    "   ```python\n",
    "   from langchain.prompts import PromptTemplate\n",
    "   prompt = PromptTemplate.from_template(\"Summarize the text: {text}\")\n",
    "   ```\n",
    "\n",
    "3. **Chains** ‚Üí Sequence of steps (Prompt ‚Üí LLM ‚Üí Output).\n",
    "\n",
    "   ```python\n",
    "   from langchain.chains import LLMChain\n",
    "   chain = LLMChain(llm=llm, prompt=prompt)\n",
    "   chain.run(\"LangChain helps build LLM apps.\")\n",
    "   ```\n",
    "\n",
    "4. **Agents** ‚Üí LLMs that decide which tool to call.\n",
    "   Example: If asked *‚ÄúWeather in London‚Äù*, agent chooses **Weather API tool**.\n",
    "\n",
    "5. **Tools** ‚Üí External actions (Google search, DB query, API call).\n",
    "\n",
    "6. **Memory** ‚Üí Keeps conversation context.\n",
    "   Example: You ask ‚ÄúWho is CEO of Tesla?‚Äù ‚Üí Next: ‚ÄúWhere did he study?‚Äù (Memory ensures ‚Äúhe‚Äù = Elon Musk).\n",
    "\n",
    "7. **Retrievers** ‚Üí Pull relevant data from vector DB.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ RAG Workflow (Retrieve + Generate)\n",
    "\n",
    "* **Retrieve** relevant context from knowledge base (PDFs, DB, web).\n",
    "* **Generate** final answer using LLM.\n",
    "\n",
    "**Example:**\n",
    "Question: *‚ÄúWhat is CRISPR used for?‚Äù*\n",
    "\n",
    "* Retriever finds relevant chunk from biotech PDF.\n",
    "* LLM generates answer: *‚ÄúCRISPR is used for gene editing‚Ä¶‚Äù*.\n",
    "\n",
    "üëâ **RAG ensures accuracy** by grounding answers in real data.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Prompt Engineering\n",
    "\n",
    "### üî∏ Zero-shot\n",
    "\n",
    "Model answers with no examples.\n",
    "\n",
    "```text\n",
    "\"Translate 'Good morning' to French.\"\n",
    "```\n",
    "\n",
    "### üî∏ Few-shot\n",
    "\n",
    "Give examples to guide model.\n",
    "\n",
    "```text\n",
    "\"English: Hello ‚Üí French: Bonjour\n",
    "English: Thanks ‚Üí French: Merci\n",
    "English: Good morning ‚Üí French:\"\n",
    "```\n",
    "\n",
    "### üî∏ PromptTemplate & Dynamic Prompts\n",
    "\n",
    "```python\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"language\", \"text\"],\n",
    "    template=\"Translate {text} into {language}.\"\n",
    ")\n",
    "```\n",
    "\n",
    "### üî∏ Guardrails & Structured Outputs\n",
    "\n",
    "```python\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"summary\", description=\"Short summary\"),\n",
    "    ResponseSchema(name=\"keywords\", description=\"Key terms\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "```\n",
    "\n",
    "üëâ This ensures the LLM always outputs JSON instead of free text.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Vector Databases\n",
    "\n",
    "### ‚ùì What are embeddings?\n",
    "\n",
    "* **Embedding = numerical representation of text** in high-dimensional space.\n",
    "* Similar texts ‚Üí vectors close to each other.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "* ‚ÄúDog‚Äù and ‚ÄúPuppy‚Äù embeddings ‚Üí close.\n",
    "* ‚ÄúDog‚Äù and ‚ÄúRocket‚Äù embeddings ‚Üí far apart.\n",
    "\n",
    "---\n",
    "\n",
    "### Popular Vector DBs\n",
    "\n",
    "* **Chroma** ‚Üí lightweight, local, good for prototyping.\n",
    "* **Pinecone** ‚Üí scalable, managed cloud DB.\n",
    "* **Weaviate** ‚Üí supports hybrid (vector + keyword).\n",
    "* **FAISS** ‚Üí open-source, in-memory (by Facebook).\n",
    "\n",
    "---\n",
    "\n",
    "### üîé Similarity Search\n",
    "\n",
    "```python\n",
    "docs = vectorstore.similarity_search(\"What is LangChain?\", k=3)\n",
    "```\n",
    "\n",
    "Retriever finds **top 3 closest docs** to query.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Memory\n",
    "\n",
    "1. **ConversationBufferMemory**\n",
    "   Stores all conversation history.\n",
    "   Good for small chatbots.\n",
    "\n",
    "2. **ConversationKGMemory**\n",
    "   Stores as **knowledge graph** (relations like *Elon ‚Üí CEO ‚Üí Tesla*).\n",
    "   Good for reasoning.\n",
    "\n",
    "3. **VectorStoreRetrieverMemory**\n",
    "   Stores embeddings of past chats.\n",
    "   Useful for **long-term memory** in assistants.\n",
    "\n",
    "üëâ **When to use?**\n",
    "\n",
    "* Chatbot with short sessions ‚Üí BufferMemory\n",
    "* Reasoning over relationships ‚Üí KGMemory\n",
    "* Long-term assistant (weeks/months) ‚Üí VectorStoreMemory\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Agents\n",
    "\n",
    "### ‚ùì Chain vs Agent\n",
    "\n",
    "* **Chain** ‚Üí Fixed steps (Prompt ‚Üí LLM ‚Üí Output).\n",
    "* **Agent** ‚Üí LLM decides which tool/step to call dynamically.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Types\n",
    "\n",
    "1. **ReAct Agent** ‚Üí Thinks + acts (e.g., chooses between calculator or web search).\n",
    "2. **Conversational Agent** ‚Üí Designed for chatbots with memory.\n",
    "3. **Tool-using Agent** ‚Üí Can call APIs like Google, SQL, or Python.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Custom Tool for Agent\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "```\n",
    "\n",
    "Now the Agent can decide to call `add_numbers` when asked.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ LangChain with External APIs\n",
    "\n",
    "1. **Loading Data**\n",
    "\n",
    "   * PDFs ‚Üí `PyPDFLoader`\n",
    "   * SQL ‚Üí `SQLDatabaseToolkit`\n",
    "   * REST ‚Üí `RequestsWrapper`\n",
    "\n",
    "2. **Connecting with LLMs**\n",
    "\n",
    "   ```python\n",
    "   from langchain_openai import ChatOpenAI\n",
    "   llm = ChatOpenAI(model=\"gpt-4\")   # OpenAI\n",
    "   ```\n",
    "\n",
    "   ```python\n",
    "   from langchain_groq import ChatGroq\n",
    "   llm = ChatGroq(model=\"mixtral\")   # Groq\n",
    "   ```\n",
    "\n",
    "3. **Pipeline Orchestration**\n",
    "   Example:\n",
    "\n",
    "   * Load PDF ‚Üí Create embeddings ‚Üí Store in Pinecone ‚Üí Build Retriever ‚Üí Use LLM for Q\\&A ‚Üí Deploy via Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ If you can explain these **with examples** in an interview, you‚Äôll stand out as **hands-on + conceptual**.\n",
    "\n",
    "---\n",
    "\n",
    "üëâ Do you want me to prepare a **‚Äú50 LangChain Interview Questions + Answers with code examples‚Äù** PDF so you can revise everything in one place?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442429c7",
   "metadata": {},
   "source": [
    "Got it üëç You want a **ready-to-use Q\\&A guide** for **LangChain + GenAI interviews**.\n",
    "I‚Äôll prepare **50 interview questions with crisp, practical answers + examples** (good for 2‚Äì6 yrs exp).\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ **Top 50 LangChain & GenAI Interview Questions & Answers**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 1: LangChain Basics**\n",
    "\n",
    "1. **Q: What is LangChain?**\n",
    "   **A:** A framework to build LLM-powered apps with modular components like LLMs, Prompts, Memory, Tools, Chains, and Agents. It abstracts complexity vs raw API calls.\n",
    "\n",
    "2. **Q: Why use LangChain instead of calling OpenAI API directly?**\n",
    "   **A:** Direct APIs don‚Äôt handle memory, chaining, retrieval, or tool execution. LangChain standardizes these into reusable workflows.\n",
    "\n",
    "3. **Q: What are the main components of LangChain?**\n",
    "   **A:**\n",
    "\n",
    "   * **LLM** (model interface)\n",
    "   * **PromptTemplate** (prompt management)\n",
    "   * **Chains** (fixed workflows)\n",
    "   * **Memory** (context/history storage)\n",
    "   * **Retrievers** (fetch docs from Vector DB)\n",
    "   * **Agents** (dynamic decision-making)\n",
    "   * **Tools** (external API/DB access)\n",
    "\n",
    "4. **Q: What is a Chain in LangChain?**\n",
    "   **A:** A sequence of steps where input ‚Üí prompt ‚Üí LLM ‚Üí output. Example: `LLMChain`.\n",
    "\n",
    "5. **Q: What is the difference between Chain and Agent?**\n",
    "   **A:**\n",
    "\n",
    "   * **Chain** = fixed workflow.\n",
    "   * **Agent** = LLM decides dynamically which tool/action to use.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 2: Prompt Engineering**\n",
    "\n",
    "6. **Q: What is zero-shot prompting?**\n",
    "   **A:** Asking an LLM to perform a task without examples.\n",
    "   *Example:* ‚ÄúTranslate to French: Hello.‚Äù\n",
    "\n",
    "7. **Q: What is few-shot prompting?**\n",
    "   **A:** Giving examples to guide output.\n",
    "   *Example:*\n",
    "\n",
    "   ```\n",
    "   English: Hello ‚Üí French: Bonjour\n",
    "   English: Good morning ‚Üí French: Bonjour\n",
    "   English: How are you? ‚Üí French:\n",
    "   ```\n",
    "\n",
    "8. **Q: What is a PromptTemplate?**\n",
    "   **A:** A structured way to create prompts with placeholders.\n",
    "\n",
    "   ```python\n",
    "   PromptTemplate(\"Translate {text} to {lang}\", [\"text\",\"lang\"])\n",
    "   ```\n",
    "\n",
    "9. **Q: How to enforce structured output (like JSON)?**\n",
    "   **A:** Use instructions + OutputParser.\n",
    "\n",
    "   ```python\n",
    "   prompt = \"Return answer in JSON: { 'answer': <text> }\"\n",
    "   ```\n",
    "\n",
    "10. **Q: What are guardrails in prompts?**\n",
    "    **A:** Safety & structure constraints that prevent hallucinations and enforce format.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 3: Vector Databases**\n",
    "\n",
    "11. **Q: What is an embedding?**\n",
    "    **A:** A numerical vector representation of text capturing semantic meaning.\n",
    "\n",
    "12. **Q: Why use embeddings in RAG?**\n",
    "    **A:** To perform semantic similarity search ‚Üí retrieve relevant docs for context.\n",
    "\n",
    "13. **Q: Name popular vector databases.**\n",
    "    **A:** Chroma (open-source), Pinecone (cloud), FAISS (local), Weaviate (graph-based).\n",
    "\n",
    "14. **Q: How does similarity search work?**\n",
    "    **A:** Finds nearest vectors (cosine similarity, dot product) to the query embedding.\n",
    "\n",
    "15. **Q: When would you choose FAISS over Pinecone?**\n",
    "    **A:** FAISS = local, lightweight, dev use. Pinecone = scalable, cloud production.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 4: RAG (Retrieve + Generate)**\n",
    "\n",
    "16. **Q: What is RAG?**\n",
    "    **A:** A pipeline where documents are retrieved from a Vector DB and passed to the LLM for generation.\n",
    "\n",
    "17. **Q: Why is RAG important?**\n",
    "    **A:** LLMs don‚Äôt have updated knowledge. RAG injects domain-specific or real-time context.\n",
    "\n",
    "18. **Q: Show code for RAG in LangChain.**\n",
    "\n",
    "```python\n",
    "from langchain.chains import RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "qa.run(\"What is the project deadline?\")\n",
    "```\n",
    "\n",
    "19. **Q: How does RAG reduce hallucination?**\n",
    "    **A:** By grounding answers in retrieved factual documents.\n",
    "\n",
    "20. **Q: Can RAG work with PDFs/SQL data?**\n",
    "    **A:** Yes ‚Üí load docs, split, embed, store in Vector DB, then query with retriever.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 5: Memory**\n",
    "\n",
    "21. **Q: What is LangChain Memory?**\n",
    "    **A:** Mechanism to store conversation history/context for continuity.\n",
    "\n",
    "22. **Q: Types of memory in LangChain?**\n",
    "\n",
    "    * BufferMemory (stores conversation as text)\n",
    "    * KGMemory (stores facts as knowledge graph)\n",
    "    * VectorStoreMemory (stores embeddings of chats)\n",
    "\n",
    "23. **Q: When to use ConversationBufferMemory?**\n",
    "    **A:** Short chats, no complex history.\n",
    "\n",
    "24. **Q: When to use ConversationKGMemory?**\n",
    "    **A:** When facts and relationships matter (knowledge graphs).\n",
    "\n",
    "25. **Q: When to use VectorStoreRetrieverMemory?**\n",
    "    **A:** For long conversations, scalable retrieval from chat history.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 6: Agents**\n",
    "\n",
    "26. **Q: What is an Agent in LangChain?**\n",
    "    **A:** LLM that selects tools/actions dynamically.\n",
    "\n",
    "27. **Q: Types of Agents?**\n",
    "\n",
    "    * ReAct (reasoning + action)\n",
    "    * Conversational\n",
    "    * Tool-using (SQL, APIs, search)\n",
    "\n",
    "28. **Q: Example use case of an Agent.**\n",
    "    **A:** LLM chooses between a calculator tool vs a Wikipedia retriever.\n",
    "\n",
    "29. **Q: Difference between ReAct agent and Chain.**\n",
    "    **A:** Chain = fixed steps. ReAct = LLM plans reasoning steps, calls tools dynamically.\n",
    "\n",
    "30. **Q: How to add custom tools to Agents?**\n",
    "    **A:** Wrap functions/APIs as `Tool()` and pass to agent.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 7: LangChain with External APIs**\n",
    "\n",
    "31. **Q: How to load PDFs into LangChain?**\n",
    "\n",
    "    ```python\n",
    "    from langchain.document_loaders import PyPDFLoader\n",
    "    loader = PyPDFLoader(\"sample.pdf\")\n",
    "    docs = loader.load()\n",
    "    ```\n",
    "\n",
    "32. **Q: How to integrate SQL DB with LangChain?**\n",
    "    Use `SQLDatabaseToolkit` to query via natural language.\n",
    "\n",
    "33. **Q: How to integrate REST APIs?**\n",
    "    Wrap requests as custom tools for agents.\n",
    "\n",
    "34. **Q: What LLMs can LangChain connect to?**\n",
    "    OpenAI, Anthropic, HuggingFace, Ollama, Groq, Cohere.\n",
    "\n",
    "35. **Q: Example: Pipeline for PDF Q\\&A bot?**\n",
    "    Load PDF ‚Üí Split ‚Üí Embed ‚Üí Store in Chroma ‚Üí Retrieve ‚Üí LLM generate answer.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 8: Advanced**\n",
    "\n",
    "36. **Q: Difference between LangChain and LlamaIndex?**\n",
    "    **A:** LangChain = orchestration framework. LlamaIndex = data indexing + retrieval optimized for RAG.\n",
    "\n",
    "37. **Q: What is an OutputParser?**\n",
    "    **A:** Converts LLM raw string output into structured format (JSON, list, dict).\n",
    "\n",
    "38. **Q: How to handle hallucinations in LangChain?**\n",
    "\n",
    "    * Use RAG (grounding)\n",
    "    * Guardrails/structured prompts\n",
    "    * Verification steps with tools\n",
    "\n",
    "39. **Q: What is the difference between retriever and vectorstore?**\n",
    "    **A:** Vectorstore = storage layer. Retriever = abstraction to fetch relevant docs.\n",
    "\n",
    "40. **Q: How to optimize LangChain pipelines?**\n",
    "\n",
    "    * Use embeddings cache\n",
    "    * Pre-chunk docs\n",
    "    * Structured prompts\n",
    "    * Async APIs\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 9: Real-World Applications**\n",
    "\n",
    "41. **Q: Example of LangChain in customer support?**\n",
    "    Chatbot with RAG pulling answers from FAQs + memory for follow-ups.\n",
    "\n",
    "42. **Q: Example in finance?**\n",
    "    Query financial reports (PDFs) ‚Üí embed ‚Üí retrieve ‚Üí generate insights.\n",
    "\n",
    "43. **Q: Example in e-commerce?**\n",
    "    Product Q\\&A chatbot with vector DB storing catalog info.\n",
    "\n",
    "44. **Q: How to build a chatbot with context?**\n",
    "    Use BufferMemory + RetrievalQA.\n",
    "\n",
    "45. **Q: How to connect LangChain to Slack/WhatsApp?**\n",
    "    Wrap LangChain pipeline in an API, connect via bot framework.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Section 10: Interview Deep Dive**\n",
    "\n",
    "46. **Q: How does LangChain enable tool use?**\n",
    "    Through Agents ‚Üí Tools ‚Üí LLM decides which tool to invoke.\n",
    "\n",
    "47. **Q: What‚Äôs the difference between synchronous and asynchronous chains?**\n",
    "    Async chains improve performance by running steps in parallel.\n",
    "\n",
    "48. **Q: What is the role of Document Loaders?**\n",
    "    They load raw data (PDF, CSV, SQL) and split into chunks for embedding.\n",
    "\n",
    "49. **Q: What are retriever types in LangChain?**\n",
    "\n",
    "    * Similarity search\n",
    "    * MMR (max marginal relevance)\n",
    "    * Self-query retrievers\n",
    "\n",
    "50. **Q: If asked to design a LangChain project in an interview?**\n",
    "    Example answer:\n",
    "\n",
    "    > I‚Äôd design a **PDF Q\\&A chatbot**. Steps: load PDF ‚Üí chunk text ‚Üí create embeddings ‚Üí store in Chroma ‚Üí Retriever ‚Üí LLM chain ‚Üí serve via API/Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "‚ö°This gives you **50 solid Q\\&As** that cover **concepts + practical examples**.\n",
    "üëâ Do you want me to prepare a **condensed 5-page PDF cheat sheet** of these so you can revise quickly before interviews?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

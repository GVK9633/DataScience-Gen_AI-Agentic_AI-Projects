{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d56f8d",
   "metadata": {},
   "source": [
    "Perfect ‚úÖ ‚Äî let‚Äôs deep dive into each topic with **simple explanations + real-world examples + interview-style clarity**.\n",
    "This way, you can **explain in interviews confidently** and even write small snippets if asked.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ LangChain Basics\n",
    "\n",
    "### ‚ùì What is LangChain? Why use it over raw APIs?\n",
    "\n",
    "* **Raw LLM API (like OpenAI GPT)** ‚Üí You send a text prompt, get back text. That‚Äôs it.\n",
    "* **LangChain** ‚Üí A framework to **orchestrate LLMs with data, memory, tools, and workflows**.\n",
    "  It makes AI apps **modular, scalable, and production-ready**.\n",
    "\n",
    "**Example:**\n",
    "Raw API ‚Üí You ask GPT: *‚ÄúSummarize a PDF.‚Äù*\n",
    "But GPT doesn‚Äôt know your PDF unless you feed entire text (expensive, impractical).\n",
    "\n",
    "LangChain ‚Üí You can:\n",
    "\n",
    "1. Load the PDF\n",
    "2. Chunk it into sections\n",
    "3. Create embeddings + store in a vector DB\n",
    "4. Use retriever to pull only relevant parts\n",
    "5. Pass to LLM for summary\n",
    "\n",
    "üëâ That‚Äôs why **LangChain > Raw APIs**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Components of LangChain\n",
    "\n",
    "1. **LLM** ‚Üí The model (OpenAI GPT, Groq, Anthropic, Llama).\n",
    "\n",
    "   ```python\n",
    "   from langchain_openai import ChatOpenAI\n",
    "   llm = ChatOpenAI(model=\"gpt-4\")\n",
    "   ```\n",
    "\n",
    "2. **PromptTemplate** ‚Üí Structured, reusable prompt.\n",
    "\n",
    "   ```python\n",
    "   from langchain.prompts import PromptTemplate\n",
    "   prompt = PromptTemplate.from_template(\"Summarize the text: {text}\")\n",
    "   ```\n",
    "\n",
    "3. **Chains** ‚Üí Sequence of steps (Prompt ‚Üí LLM ‚Üí Output).\n",
    "\n",
    "   ```python\n",
    "   from langchain.chains import LLMChain\n",
    "   chain = LLMChain(llm=llm, prompt=prompt)\n",
    "   chain.run(\"LangChain helps build LLM apps.\")\n",
    "   ```\n",
    "\n",
    "4. **Agents** ‚Üí LLMs that decide which tool to call.\n",
    "   Example: If asked *‚ÄúWeather in London‚Äù*, agent chooses **Weather API tool**.\n",
    "\n",
    "5. **Tools** ‚Üí External actions (Google search, DB query, API call).\n",
    "\n",
    "6. **Memory** ‚Üí Keeps conversation context.\n",
    "   Example: You ask ‚ÄúWho is CEO of Tesla?‚Äù ‚Üí Next: ‚ÄúWhere did he study?‚Äù (Memory ensures ‚Äúhe‚Äù = Elon Musk).\n",
    "\n",
    "7. **Retrievers** ‚Üí Pull relevant data from vector DB.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ RAG Workflow (Retrieve + Generate)\n",
    "\n",
    "* **Retrieve** relevant context from knowledge base (PDFs, DB, web).\n",
    "* **Generate** final answer using LLM.\n",
    "\n",
    "**Example:**\n",
    "Question: *‚ÄúWhat is CRISPR used for?‚Äù*\n",
    "\n",
    "* Retriever finds relevant chunk from biotech PDF.\n",
    "* LLM generates answer: *‚ÄúCRISPR is used for gene editing‚Ä¶‚Äù*.\n",
    "\n",
    "üëâ **RAG ensures accuracy** by grounding answers in real data.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Prompt Engineering\n",
    "\n",
    "### üî∏ Zero-shot\n",
    "\n",
    "Model answers with no examples.\n",
    "\n",
    "```text\n",
    "\"Translate 'Good morning' to French.\"\n",
    "```\n",
    "\n",
    "### üî∏ Few-shot\n",
    "\n",
    "Give examples to guide model.\n",
    "\n",
    "```text\n",
    "\"English: Hello ‚Üí French: Bonjour\n",
    "English: Thanks ‚Üí French: Merci\n",
    "English: Good morning ‚Üí French:\"\n",
    "```\n",
    "\n",
    "### üî∏ PromptTemplate & Dynamic Prompts\n",
    "\n",
    "```python\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"language\", \"text\"],\n",
    "    template=\"Translate {text} into {language}.\"\n",
    ")\n",
    "```\n",
    "\n",
    "### üî∏ Guardrails & Structured Outputs\n",
    "\n",
    "```python\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"summary\", description=\"Short summary\"),\n",
    "    ResponseSchema(name=\"keywords\", description=\"Key terms\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "```\n",
    "\n",
    "üëâ This ensures the LLM always outputs JSON instead of free text.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Vector Databases\n",
    "\n",
    "### ‚ùì What are embeddings?\n",
    "\n",
    "* **Embedding = numerical representation of text** in high-dimensional space.\n",
    "* Similar texts ‚Üí vectors close to each other.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "* ‚ÄúDog‚Äù and ‚ÄúPuppy‚Äù embeddings ‚Üí close.\n",
    "* ‚ÄúDog‚Äù and ‚ÄúRocket‚Äù embeddings ‚Üí far apart.\n",
    "\n",
    "---\n",
    "\n",
    "### Popular Vector DBs\n",
    "\n",
    "* **Chroma** ‚Üí lightweight, local, good for prototyping.\n",
    "* **Pinecone** ‚Üí scalable, managed cloud DB.\n",
    "* **Weaviate** ‚Üí supports hybrid (vector + keyword).\n",
    "* **FAISS** ‚Üí open-source, in-memory (by Facebook).\n",
    "\n",
    "---\n",
    "\n",
    "### üîé Similarity Search\n",
    "\n",
    "```python\n",
    "docs = vectorstore.similarity_search(\"What is LangChain?\", k=3)\n",
    "```\n",
    "\n",
    "Retriever finds **top 3 closest docs** to query.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Memory\n",
    "\n",
    "1. **ConversationBufferMemory**\n",
    "   Stores all conversation history.\n",
    "   Good for small chatbots.\n",
    "\n",
    "2. **ConversationKGMemory**\n",
    "   Stores as **knowledge graph** (relations like *Elon ‚Üí CEO ‚Üí Tesla*).\n",
    "   Good for reasoning.\n",
    "\n",
    "3. **VectorStoreRetrieverMemory**\n",
    "   Stores embeddings of past chats.\n",
    "   Useful for **long-term memory** in assistants.\n",
    "\n",
    "üëâ **When to use?**\n",
    "\n",
    "* Chatbot with short sessions ‚Üí BufferMemory\n",
    "* Reasoning over relationships ‚Üí KGMemory\n",
    "* Long-term assistant (weeks/months) ‚Üí VectorStoreMemory\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Agents\n",
    "\n",
    "### ‚ùì Chain vs Agent\n",
    "\n",
    "* **Chain** ‚Üí Fixed steps (Prompt ‚Üí LLM ‚Üí Output).\n",
    "* **Agent** ‚Üí LLM decides which tool/step to call dynamically.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Types\n",
    "\n",
    "1. **ReAct Agent** ‚Üí Thinks + acts (e.g., chooses between calculator or web search).\n",
    "2. **Conversational Agent** ‚Üí Designed for chatbots with memory.\n",
    "3. **Tool-using Agent** ‚Üí Can call APIs like Google, SQL, or Python.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Custom Tool for Agent\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "```\n",
    "\n",
    "Now the Agent can decide to call `add_numbers` when asked.\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ LangChain with External APIs\n",
    "\n",
    "1. **Loading Data**\n",
    "\n",
    "   * PDFs ‚Üí `PyPDFLoader`\n",
    "   * SQL ‚Üí `SQLDatabaseToolkit`\n",
    "   * REST ‚Üí `RequestsWrapper`\n",
    "\n",
    "2. **Connecting with LLMs**\n",
    "\n",
    "   ```python\n",
    "   from langchain_openai import ChatOpenAI\n",
    "   llm = ChatOpenAI(model=\"gpt-4\")   # OpenAI\n",
    "   ```\n",
    "\n",
    "   ```python\n",
    "   from langchain_groq import ChatGroq\n",
    "   llm = ChatGroq(model=\"mixtral\")   # Groq\n",
    "   ```\n",
    "\n",
    "3. **Pipeline Orchestration**\n",
    "   Example:\n",
    "\n",
    "   * Load PDF ‚Üí Create embeddings ‚Üí Store in Pinecone ‚Üí Build Retriever ‚Üí Use LLM for Q\\&A ‚Üí Deploy via Streamlit.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ If you can explain these **with examples** in an interview, you‚Äôll stand out as **hands-on + conceptual**.\n",
    "\n",
    "---\n",
    "\n",
    "üëâ Do you want me to prepare a **‚Äú50 LangChain Interview Questions + Answers with code examples‚Äù** PDF so you can revise everything in one place?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
